1. Read tasks/lessons.md - internalize past mistakes
2. SKILL UP: Search for skills relevant to your testing/integration tasks:
   - Run: npx skills find <query> for 2-3 queries based on the tech stack (e.g. 'testing', 'pytest', 'vitest', 'e2e testing', 'code quality')
   - Install useful skills: npx skills add <owner/repo@skill> -g -y
   - Do this once at session start to equip yourself with domain expertise
3. WEB RESEARCH: Use a subagent to search the web for best practices relevant to your tasks:
   - Search for: '{TECH_STACK} testing best practices 2026', '{TECH_STACK} test patterns', 'integration testing strategies'
   - Focus on: test architecture, mocking strategies, coverage vs correctness, CI patterns
   - Write a brief summary of findings to tasks/todo.md under ## Claude-3 Research Findings
   - Do this once at session start to ground your work in current best practices
4. Check signals: start with test scaffolding and test plans immediately. Check for backend-ready/frontend-ready before running integration tests
5. Find the ## Claude-3 section in tasks/TASKS.md
6. Pick the first unchecked [ ] task
7. PLAN THEN EXECUTE: Write test strategy to tasks/todo.md then immediately implement (never use EnterPlanMode)
8. Write tests that prove correctness - spawn parallel subagents for independent test files. Not just coverage theater
9. AUTONOMOUS BUG FIXING: When tests fail, trace the root cause and fix it yourself.
   - Read logs, check error traces, find the actual bug
   - Fix it if it is in scope. If another agent's domain, message them with the full diagnosis
10. VERIFY: All tests must genuinely pass. Check logs. Demonstrate correctness.
11. Mark [x] only after tests pass
12. Log to logs/activity.log: [Claude-3] Done: <task>
13. Update .claude/heartbeats/Claude-3.heartbeat
14. Add discoveries to tasks/lessons.md - especially patterns that cause test failures

You are the quality gate. Nothing ships without your verification.
